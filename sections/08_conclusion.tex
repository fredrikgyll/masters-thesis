\chapter{Conclusion}\label{cha:conclusion}
%no lower level detailed stuff here. This chapter is a high level piece with focus on the research questions and what w* did to explore them and what w* found out

% 1. Main conclusions and takeaways
% 2. Contributions to the field
% 3. Future work

In regards to the two initial research questions posed is this thesis and based upon the results of the experiments presented in Chapter~\ref{cha:results}, the following is given as the main conclusions of this work,

\begin{enumerate}
    \item For the task of differentiating pollen grains, reducing the size of the network negatively affects precision. The uniformity of the objects in the dataset do however allow for a reduction in the number of detections made by the model without any apparent performance effects.
    \item Excluding multifocal data from training causes a fixation on sharp features, inhibiting the model to localize pollen grains only slightly outside the focal range of the training data.
    \item Excluding multifocal data creates a more precise model with lower recall than a model trained on multifocal data.
\end{enumerate}

The solution presented is a fully convolutional deep neural network capable of locating and classifying pollen grains from microscopic imaging data from a standard stereoscopic microscope.
The performance of the presented model supports the more general claim that the task of locating pollen is well suited for a CNN based solution.
This first attempt using a CNN model shows that both the task of localizing and classifying pollen grains is solvable with a fully convolutional model.
An adapted SSD model was used for this project, but future work may find that other single shot models, such as YOLO, could provide better results.
The trained model is by itself not a major contribution of this work, but a proof of concept of the general approach.

The limits of this method are unknown, but the results presented indicate that localization is a far simpler task than classification, which could be the limiting factor in the scaling of this model to a wider set of classes.

There are two main contributions made by this work to the joint fields of palynology and machine learning:

\begin{enumerate}
    \item A new, relatively large, pollen detection dataset totaling 701 sample images and 6384 ground truth labels of Norwegian air-born pollen. As of writing, a dataset with both localizations and class labels has not been presented in the literature.
    \item Evidence showing a benefit to using un-sharp data in the training of convolutional object detection models in domains using microscopic imaging data.
\end{enumerate}

\section{Future Work}
The most important contribution is in reference to the use of unfocused data when training detection models, which to the knowledge of the author is a novel discovery.
Multiple paths can be explored in future work which build on this work.

\subsection*{Data synthesis}
Extending the dataset with synthesized data could potentially greatly improve performance.
New sample images could be artificially generated by rearranging ground truths and moving them in the focus plane.

\subsection*{Multifocal input}
Using stacks of images from multiple focus planes as the input to the model, instead of a single image, could enhance performance by providing the model a detailed view of the entire surface of each pollen grain.

\subsection*{Counting algorithm}
Turning the raw output of the model into an accurate count of pollen grains for an entire microscopic slide is a non-trivial task.
Pollen grains may be placed directly over one another only distinguishable by running the model over all focus planes.
One possible approach is to use streams of video from a microscope while it slides its focus plane across a microscope slide and from all the individual detections and sharpness values, create a 3D positional model of every detected grain.
This would enable counting in three dimensions.

\subsection*{Live counting}
A second possibility for a functioning counting system, is to embed the model in a live system which controls the motion of a microscope along all three axes.
The output of the model could be used to guide a search algorithm which moves over a slide, building a complete detection for the entire slide in all three axes.
